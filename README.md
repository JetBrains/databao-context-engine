[![official project](https://jb.gg/badges/official.svg)](https://confluence.jetbrains.com/display/ALL/JetBrains+on+GitHub)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/JetBrains/databao-context-engine/blob/main/LICENSE)

[//]: # ([![PyPI version]&#40;https://img.shields.io/pypi/v/databao-context-engine.svg&#41;]&#40;https://pypi.org/project/databao-context-engine&#41;)

[//]: # ([![Python versions]&#40;https://img.shields.io/pypi/pyversions/databao-context-engine.svg&#41;]&#40;https://pypi.org/project/databao-context-engine/&#41;)


<h1 align="center">Databao Context Engine</h1>
<p align="center">
 <b>Semantic context for your LLMs — generated automatically.</b><br/>
 No more copying schemas. No manual documentation. Just accurate answers.
</p>
<p align="center">
 <a href="https://databao.app">Website</a> 

[//]: # (•)

[//]: # ( <a href="#quickstart">Quickstart</a> •)

[//]: # ( <a href="#supported-data-sources">Data Sources</a> •)

[//]: # ( <a href="#contributing">Contributing</a>)
</p>

---

## What is Databao Context Engine?

Databao Context Engine **automatically generates governed semantic context** from your databases, BI tools, documents, and spreadsheets.

Integrate it with any LLM to deliver **accurate, context-aware answers** — without copying schemas or writing documentation by hand.

```
Your data sources → Context Engine → Unified semantic graph → Any LLM
```

## Why choose Databao Context Engine?

| Feature                    | What it means for you                                          |
|----------------------------|----------------------------------------------------------------|
| **Auto-generated context** | Extracts schemas, relationships, and semantics automatically   |
| **Runs locally**           | Your data never leaves your environment                        |
| **MCP integration**        | Works with Claude Desktop, Cursor, and any MCP-compatible tool |
| **Multiple sources**       | Databases, dbt projects, spreadsheets, documents               |
| **Built-in benchmarks**    | Measure and improve context quality over time                  |
| **LLM agnostic**           | OpenAI, Anthropic, Ollama, Gemini — use any model              |
| **Governed & versioned**   | Track, version, and share context across your team             |
| **Dynamic or static**      | Serve context via MCP server or export as artifact             |
